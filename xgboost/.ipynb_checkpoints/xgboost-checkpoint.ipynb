{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_validate, RepeatedKFold\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score,r2_score\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_pkill.csv', delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt_sht</th>\n",
       "      <th>vel_sht</th>\n",
       "      <th>pit_sht</th>\n",
       "      <th>alt_tgt</th>\n",
       "      <th>vel_tgt</th>\n",
       "      <th>hdg_tgt</th>\n",
       "      <th>rgt_tgt</th>\n",
       "      <th>dist</th>\n",
       "      <th>delay</th>\n",
       "      <th>turn_dg</th>\n",
       "      <th>pkill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900.094833</td>\n",
       "      <td>516.257515</td>\n",
       "      <td>-9.115002</td>\n",
       "      <td>9411.674491</td>\n",
       "      <td>389.059516</td>\n",
       "      <td>-179.508724</td>\n",
       "      <td>28.173016</td>\n",
       "      <td>22.107204</td>\n",
       "      <td>24.962478</td>\n",
       "      <td>5.107690</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1668.030968</td>\n",
       "      <td>384.114554</td>\n",
       "      <td>-9.291737</td>\n",
       "      <td>6424.170046</td>\n",
       "      <td>538.332386</td>\n",
       "      <td>150.564222</td>\n",
       "      <td>21.635788</td>\n",
       "      <td>42.957053</td>\n",
       "      <td>27.889110</td>\n",
       "      <td>140.635249</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430.046650</td>\n",
       "      <td>552.946387</td>\n",
       "      <td>-16.802029</td>\n",
       "      <td>11292.969864</td>\n",
       "      <td>536.495037</td>\n",
       "      <td>-71.258760</td>\n",
       "      <td>47.099787</td>\n",
       "      <td>17.904767</td>\n",
       "      <td>28.814680</td>\n",
       "      <td>13.967480</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1819.812543</td>\n",
       "      <td>524.681447</td>\n",
       "      <td>2.326836</td>\n",
       "      <td>3983.583185</td>\n",
       "      <td>354.232941</td>\n",
       "      <td>-147.655375</td>\n",
       "      <td>-25.450868</td>\n",
       "      <td>38.858097</td>\n",
       "      <td>25.736859</td>\n",
       "      <td>47.110727</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1348.600786</td>\n",
       "      <td>367.370819</td>\n",
       "      <td>13.801087</td>\n",
       "      <td>8269.417066</td>\n",
       "      <td>533.015720</td>\n",
       "      <td>85.274320</td>\n",
       "      <td>-47.226769</td>\n",
       "      <td>27.176054</td>\n",
       "      <td>17.912385</td>\n",
       "      <td>137.619306</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855050</th>\n",
       "      <td>44376.436551</td>\n",
       "      <td>544.473934</td>\n",
       "      <td>-4.773440</td>\n",
       "      <td>16868.508237</td>\n",
       "      <td>620.848721</td>\n",
       "      <td>83.157352</td>\n",
       "      <td>32.501000</td>\n",
       "      <td>32.909110</td>\n",
       "      <td>21.978916</td>\n",
       "      <td>71.510008</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855051</th>\n",
       "      <td>44396.062176</td>\n",
       "      <td>555.458863</td>\n",
       "      <td>-12.651975</td>\n",
       "      <td>44331.857296</td>\n",
       "      <td>626.047542</td>\n",
       "      <td>28.146378</td>\n",
       "      <td>-26.005787</td>\n",
       "      <td>42.962424</td>\n",
       "      <td>27.934929</td>\n",
       "      <td>145.538436</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855052</th>\n",
       "      <td>44373.716110</td>\n",
       "      <td>609.965112</td>\n",
       "      <td>-24.517640</td>\n",
       "      <td>16754.178594</td>\n",
       "      <td>580.015564</td>\n",
       "      <td>168.638639</td>\n",
       "      <td>-16.550910</td>\n",
       "      <td>43.350364</td>\n",
       "      <td>15.081863</td>\n",
       "      <td>79.534893</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855053</th>\n",
       "      <td>44432.347726</td>\n",
       "      <td>617.846742</td>\n",
       "      <td>11.024131</td>\n",
       "      <td>24860.378262</td>\n",
       "      <td>658.322238</td>\n",
       "      <td>-145.516952</td>\n",
       "      <td>14.465779</td>\n",
       "      <td>40.760772</td>\n",
       "      <td>26.462078</td>\n",
       "      <td>84.072836</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855054</th>\n",
       "      <td>44678.656616</td>\n",
       "      <td>558.896145</td>\n",
       "      <td>16.252619</td>\n",
       "      <td>19450.140698</td>\n",
       "      <td>644.534022</td>\n",
       "      <td>-63.727657</td>\n",
       "      <td>-52.439259</td>\n",
       "      <td>35.887900</td>\n",
       "      <td>16.159216</td>\n",
       "      <td>41.072911</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2855055 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              alt_sht     vel_sht    pit_sht       alt_tgt     vel_tgt  \\\n",
       "0         1900.094833  516.257515  -9.115002   9411.674491  389.059516   \n",
       "1         1668.030968  384.114554  -9.291737   6424.170046  538.332386   \n",
       "2         1430.046650  552.946387 -16.802029  11292.969864  536.495037   \n",
       "3         1819.812543  524.681447   2.326836   3983.583185  354.232941   \n",
       "4         1348.600786  367.370819  13.801087   8269.417066  533.015720   \n",
       "...               ...         ...        ...           ...         ...   \n",
       "2855050  44376.436551  544.473934  -4.773440  16868.508237  620.848721   \n",
       "2855051  44396.062176  555.458863 -12.651975  44331.857296  626.047542   \n",
       "2855052  44373.716110  609.965112 -24.517640  16754.178594  580.015564   \n",
       "2855053  44432.347726  617.846742  11.024131  24860.378262  658.322238   \n",
       "2855054  44678.656616  558.896145  16.252619  19450.140698  644.534022   \n",
       "\n",
       "            hdg_tgt    rgt_tgt       dist      delay     turn_dg  pkill  \n",
       "0       -179.508724  28.173016  22.107204  24.962478    5.107690  0.087  \n",
       "1        150.564222  21.635788  42.957053  27.889110  140.635249  0.016  \n",
       "2        -71.258760  47.099787  17.904767  28.814680   13.967480  0.070  \n",
       "3       -147.655375 -25.450868  38.858097  25.736859   47.110727  0.020  \n",
       "4         85.274320 -47.226769  27.176054  17.912385  137.619306  0.024  \n",
       "...             ...        ...        ...        ...         ...    ...  \n",
       "2855050   83.157352  32.501000  32.909110  21.978916   71.510008  0.031  \n",
       "2855051   28.146378 -26.005787  42.962424  27.934929  145.538436  0.024  \n",
       "2855052  168.638639 -16.550910  43.350364  15.081863   79.534893  0.043  \n",
       "2855053 -145.516952  14.465779  40.760772  26.462078   84.072836  0.111  \n",
       "2855054  -63.727657 -52.439259  35.887900  16.159216   41.072911  0.031  \n",
       "\n",
       "[2855055 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['pkill'],axis=1)\n",
    "y = df['pkill']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [1_000_000],\n",
    "                  'max_depth': [10, 12, 14, 16, 18, 20],\n",
    "                  'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "                  'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "                  'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "                  'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "                  'min_child_weight':[1, 3, 5], \n",
    "                  'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "                  'n_jobs': [-1]\n",
    "                  }\n",
    "\n",
    "n_iter = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dic, path_to_save, filename):\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    a_file = open(f'{path_to_save}{filename}.pkl', \"wb\")\n",
    "    pickle.dump(dic, a_file)\n",
    "    a_file.close()\n",
    "    \n",
    "def save_dict_csv(dic, path_to_save, filename):\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "    with open(f'{path_to_save}{filename}.csv', 'w') as f:\n",
    "        for k in dic.keys():\n",
    "            f.write(\"%s,%s\\n\" % (k, dic[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaciton #37:\n",
      "{'n_estimators': 1000000, 'max_depth': 14, 'learning_rate': 0.3, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.7, 'min_child_weight': 5, 'gamma': 0.2, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:30.46856\tvalidation_1-rmse:30.86277\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,n_iter+1):\n",
    "    if n<=36:\n",
    "        continue\n",
    "        \n",
    "    print(f'\\nInteraciton #{n}:')\n",
    "\n",
    "    metrics = pd.DataFrame(columns=['fold', 'mae', 'mse', 'rmse', 'r2', 'training_time', 'inference_time'])\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    \n",
    "    # Choosing the hyperparameters\n",
    "    params_chosen = {}\n",
    "    for id, item in params.items():\n",
    "        params_chosen[id] = random.choice(item)\n",
    "    print(params_chosen)\n",
    "    # Saving the hyperparameters\n",
    "    save_dict_csv(params_chosen, f'./hyperparameters/', f'{n}')\n",
    "    \n",
    "    # Training\n",
    "    for train, val in kfold.split(X_train, y_train):\n",
    "                \n",
    "        # Define the model as the best model from the random search\n",
    "        model = xgb.XGBRegressor(**params_chosen)\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "        # get the start time\n",
    "        st_wall = time.time()\n",
    "        \n",
    "        # Fit data to model\n",
    "        model.fit(X_train[train], y_train[train], eval_metric=['rmse'], verbose=50, eval_set=[(X_train[train], y_train[train]), (X_train[val], y_train[val])], early_stopping_rounds=patience)\n",
    "\n",
    "        # get the end time\n",
    "        et_wall = time.time()\n",
    "\n",
    "        # get execution time\n",
    "        wall_time = et_wall - st_wall\n",
    "\n",
    "        print('Training Execution time:', wall_time, 'seconds')\n",
    "\n",
    "        # get the start time\n",
    "        st_wall_inf = time.time()\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # get the end time\n",
    "        et_wall_inf = time.time()\n",
    "\n",
    "        # get execution time\n",
    "        wall_time_inf = et_wall_inf - st_wall_inf\n",
    "\n",
    "        print('Inference Execution time:', wall_time_inf, 'seconds')\n",
    "\n",
    "        scores = [fold_no, mean_absolute_error(y_test, y_pred), mean_squared_error(y_test, y_pred), \n",
    "                  sqrt(mean_squared_error(y_test, y_pred)), r2_score(y_test, y_pred), wall_time, wall_time_inf]\n",
    "\n",
    "        metrics.loc[len(metrics)] = scores\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "    metrics.loc[len(metrics)] = ['mean', metrics['mae'].mean(), metrics['mse'].mean(), metrics['rmse'].mean(), metrics['r2'].mean(), metrics['training_time'].mean(), metrics['inference_time'].mean()]\n",
    "    metrics.loc[len(metrics)] = ['std', metrics['mae'].iloc[:-1].std(), metrics['mse'].iloc[:-1].std(), metrics['rmse'].iloc[:-1].std(), metrics['r2'].iloc[:-1].std(), metrics['training_time'].iloc[:-1].std(), metrics['inference_time'].iloc[:-1].std()]  \n",
    "    metrics.loc[len(metrics)] = ['sum', metrics['mae'].iloc[:-2].sum(), metrics['mse'].iloc[:-2].sum(), metrics['rmse'].iloc[:-2].sum(), metrics['r2'].iloc[:-2].sum(), metrics['training_time'].iloc[:-2].sum(), metrics['inference_time'].iloc[:-2].sum()]\n",
    "    metrics = metrics.set_index('fold')\n",
    "\n",
    "    path_to_save = f'./results/'\n",
    "\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    metrics.to_csv(f'{path_to_save}{n}.csv')\n",
    "    \n",
    "    path_to_save = f'./models/'\n",
    "\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "    \n",
    "    # save model to file\n",
    "    joblib.dump(model, f'{path_to_save}{n}.dat');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work-asa]",
   "language": "python",
   "name": "conda-env-work-asa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
