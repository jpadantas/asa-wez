{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_validate, RepeatedKFold\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score,r2_score\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_pkill.csv', delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt_sht</th>\n",
       "      <th>vel_sht</th>\n",
       "      <th>pit_sht</th>\n",
       "      <th>alt_tgt</th>\n",
       "      <th>vel_tgt</th>\n",
       "      <th>hdg_tgt</th>\n",
       "      <th>rgt_tgt</th>\n",
       "      <th>dist</th>\n",
       "      <th>delay</th>\n",
       "      <th>turn_dg</th>\n",
       "      <th>pkill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900.094833</td>\n",
       "      <td>516.257515</td>\n",
       "      <td>-9.115002</td>\n",
       "      <td>9411.674491</td>\n",
       "      <td>389.059516</td>\n",
       "      <td>-179.508724</td>\n",
       "      <td>28.173016</td>\n",
       "      <td>22.107204</td>\n",
       "      <td>24.962478</td>\n",
       "      <td>5.107690</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1668.030968</td>\n",
       "      <td>384.114554</td>\n",
       "      <td>-9.291737</td>\n",
       "      <td>6424.170046</td>\n",
       "      <td>538.332386</td>\n",
       "      <td>150.564222</td>\n",
       "      <td>21.635788</td>\n",
       "      <td>42.957053</td>\n",
       "      <td>27.889110</td>\n",
       "      <td>140.635249</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430.046650</td>\n",
       "      <td>552.946387</td>\n",
       "      <td>-16.802029</td>\n",
       "      <td>11292.969864</td>\n",
       "      <td>536.495037</td>\n",
       "      <td>-71.258760</td>\n",
       "      <td>47.099787</td>\n",
       "      <td>17.904767</td>\n",
       "      <td>28.814680</td>\n",
       "      <td>13.967480</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1819.812543</td>\n",
       "      <td>524.681447</td>\n",
       "      <td>2.326836</td>\n",
       "      <td>3983.583185</td>\n",
       "      <td>354.232941</td>\n",
       "      <td>-147.655375</td>\n",
       "      <td>-25.450868</td>\n",
       "      <td>38.858097</td>\n",
       "      <td>25.736859</td>\n",
       "      <td>47.110727</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1348.600786</td>\n",
       "      <td>367.370819</td>\n",
       "      <td>13.801087</td>\n",
       "      <td>8269.417066</td>\n",
       "      <td>533.015720</td>\n",
       "      <td>85.274320</td>\n",
       "      <td>-47.226769</td>\n",
       "      <td>27.176054</td>\n",
       "      <td>17.912385</td>\n",
       "      <td>137.619306</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855050</th>\n",
       "      <td>44376.436551</td>\n",
       "      <td>544.473934</td>\n",
       "      <td>-4.773440</td>\n",
       "      <td>16868.508237</td>\n",
       "      <td>620.848721</td>\n",
       "      <td>83.157352</td>\n",
       "      <td>32.501000</td>\n",
       "      <td>32.909110</td>\n",
       "      <td>21.978916</td>\n",
       "      <td>71.510008</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855051</th>\n",
       "      <td>44396.062176</td>\n",
       "      <td>555.458863</td>\n",
       "      <td>-12.651975</td>\n",
       "      <td>44331.857296</td>\n",
       "      <td>626.047542</td>\n",
       "      <td>28.146378</td>\n",
       "      <td>-26.005787</td>\n",
       "      <td>42.962424</td>\n",
       "      <td>27.934929</td>\n",
       "      <td>145.538436</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855052</th>\n",
       "      <td>44373.716110</td>\n",
       "      <td>609.965112</td>\n",
       "      <td>-24.517640</td>\n",
       "      <td>16754.178594</td>\n",
       "      <td>580.015564</td>\n",
       "      <td>168.638639</td>\n",
       "      <td>-16.550910</td>\n",
       "      <td>43.350364</td>\n",
       "      <td>15.081863</td>\n",
       "      <td>79.534893</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855053</th>\n",
       "      <td>44432.347726</td>\n",
       "      <td>617.846742</td>\n",
       "      <td>11.024131</td>\n",
       "      <td>24860.378262</td>\n",
       "      <td>658.322238</td>\n",
       "      <td>-145.516952</td>\n",
       "      <td>14.465779</td>\n",
       "      <td>40.760772</td>\n",
       "      <td>26.462078</td>\n",
       "      <td>84.072836</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855054</th>\n",
       "      <td>44678.656616</td>\n",
       "      <td>558.896145</td>\n",
       "      <td>16.252619</td>\n",
       "      <td>19450.140698</td>\n",
       "      <td>644.534022</td>\n",
       "      <td>-63.727657</td>\n",
       "      <td>-52.439259</td>\n",
       "      <td>35.887900</td>\n",
       "      <td>16.159216</td>\n",
       "      <td>41.072911</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2855055 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              alt_sht     vel_sht    pit_sht       alt_tgt     vel_tgt  \\\n",
       "0         1900.094833  516.257515  -9.115002   9411.674491  389.059516   \n",
       "1         1668.030968  384.114554  -9.291737   6424.170046  538.332386   \n",
       "2         1430.046650  552.946387 -16.802029  11292.969864  536.495037   \n",
       "3         1819.812543  524.681447   2.326836   3983.583185  354.232941   \n",
       "4         1348.600786  367.370819  13.801087   8269.417066  533.015720   \n",
       "...               ...         ...        ...           ...         ...   \n",
       "2855050  44376.436551  544.473934  -4.773440  16868.508237  620.848721   \n",
       "2855051  44396.062176  555.458863 -12.651975  44331.857296  626.047542   \n",
       "2855052  44373.716110  609.965112 -24.517640  16754.178594  580.015564   \n",
       "2855053  44432.347726  617.846742  11.024131  24860.378262  658.322238   \n",
       "2855054  44678.656616  558.896145  16.252619  19450.140698  644.534022   \n",
       "\n",
       "            hdg_tgt    rgt_tgt       dist      delay     turn_dg  pkill  \n",
       "0       -179.508724  28.173016  22.107204  24.962478    5.107690  0.087  \n",
       "1        150.564222  21.635788  42.957053  27.889110  140.635249  0.016  \n",
       "2        -71.258760  47.099787  17.904767  28.814680   13.967480  0.070  \n",
       "3       -147.655375 -25.450868  38.858097  25.736859   47.110727  0.020  \n",
       "4         85.274320 -47.226769  27.176054  17.912385  137.619306  0.024  \n",
       "...             ...        ...        ...        ...         ...    ...  \n",
       "2855050   83.157352  32.501000  32.909110  21.978916   71.510008  0.031  \n",
       "2855051   28.146378 -26.005787  42.962424  27.934929  145.538436  0.024  \n",
       "2855052  168.638639 -16.550910  43.350364  15.081863   79.534893  0.043  \n",
       "2855053 -145.516952  14.465779  40.760772  26.462078   84.072836  0.111  \n",
       "2855054  -63.727657 -52.439259  35.887900  16.159216   41.072911  0.031  \n",
       "\n",
       "[2855055 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['pkill'],axis=1)\n",
    "y = df['pkill']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [1_000_000],\n",
    "          'max_depth': [10, 12, 14, 16, 18, 20],\n",
    "          'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "          'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "          'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "          'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "          'min_child_weight':[1, 3, 5], \n",
    "          'gamma': [ 0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "          'n_jobs': [-1]\n",
    "         }\n",
    "\n",
    "n_iter = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dic, path_to_save, filename):\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    a_file = open(f'{path_to_save}{filename}.pkl', \"wb\")\n",
    "    pickle.dump(dic, a_file)\n",
    "    a_file.close()\n",
    "    \n",
    "def save_dict_csv(dic, path_to_save, filename):\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "    with open(f'{path_to_save}{filename}.csv', 'w') as f:\n",
    "        for k in dic.keys():\n",
    "            f.write(\"%s,%s\\n\" % (k, dic[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interaciton #43:\n",
      "{'n_estimators': 1000000, 'max_depth': 16, 'learning_rate': 0.1, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.7999999999999999, 'min_child_weight': 1, 'gamma': 0.1, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:32.17345\tvalidation_1-rmse:32.37174\n",
      "[50]\tvalidation_0-rmse:10.44451\tvalidation_1-rmse:16.74049\n",
      "[100]\tvalidation_0-rmse:7.51325\tvalidation_1-rmse:15.81255\n",
      "[150]\tvalidation_0-rmse:6.15356\tvalidation_1-rmse:15.24820\n",
      "[200]\tvalidation_0-rmse:5.63837\tvalidation_1-rmse:15.06811\n",
      "[250]\tvalidation_0-rmse:5.37177\tvalidation_1-rmse:15.01190\n",
      "[300]\tvalidation_0-rmse:5.15599\tvalidation_1-rmse:14.94900\n",
      "[350]\tvalidation_0-rmse:4.91374\tvalidation_1-rmse:14.90232\n",
      "[400]\tvalidation_0-rmse:4.71363\tvalidation_1-rmse:14.85876\n",
      "[429]\tvalidation_0-rmse:4.61369\tvalidation_1-rmse:14.83681\n",
      "Training Execution time: 1020.9230089187622 seconds\n",
      "Inference Execution time: 1.7297520637512207 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:32.16144\tvalidation_1-rmse:32.41233\n",
      "[50]\tvalidation_0-rmse:10.43314\tvalidation_1-rmse:16.77662\n",
      "[100]\tvalidation_0-rmse:7.50274\tvalidation_1-rmse:15.83823\n",
      "[150]\tvalidation_0-rmse:6.00638\tvalidation_1-rmse:15.18022\n",
      "[200]\tvalidation_0-rmse:5.54594\tvalidation_1-rmse:15.02390\n",
      "[250]\tvalidation_0-rmse:5.29317\tvalidation_1-rmse:14.96590\n",
      "[300]\tvalidation_0-rmse:5.06118\tvalidation_1-rmse:14.91449\n",
      "[350]\tvalidation_0-rmse:4.89934\tvalidation_1-rmse:14.89303\n",
      "[400]\tvalidation_0-rmse:4.73932\tvalidation_1-rmse:14.87765\n",
      "[450]\tvalidation_0-rmse:4.57084\tvalidation_1-rmse:14.84437\n",
      "[460]\tvalidation_0-rmse:4.55444\tvalidation_1-rmse:14.84470\n",
      "Training Execution time: 1099.2045798301697 seconds\n",
      "Inference Execution time: 1.801076889038086 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "[0]\tvalidation_0-rmse:32.16110\tvalidation_1-rmse:32.39685\n",
      "[50]\tvalidation_0-rmse:10.44496\tvalidation_1-rmse:16.74946\n",
      "[100]\tvalidation_0-rmse:7.49991\tvalidation_1-rmse:15.81517\n",
      "[150]\tvalidation_0-rmse:6.10955\tvalidation_1-rmse:15.20091\n",
      "[191]\tvalidation_0-rmse:5.70280\tvalidation_1-rmse:15.04655\n",
      "Training Execution time: 491.05697655677795 seconds\n",
      "Inference Execution time: 1.0819306373596191 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "[0]\tvalidation_0-rmse:32.17430\tvalidation_1-rmse:32.34697\n",
      "[50]\tvalidation_0-rmse:10.46547\tvalidation_1-rmse:16.72895\n",
      "[100]\tvalidation_0-rmse:7.54393\tvalidation_1-rmse:15.79643\n",
      "[150]\tvalidation_0-rmse:6.10610\tvalidation_1-rmse:15.14940\n",
      "[191]\tvalidation_0-rmse:5.60146\tvalidation_1-rmse:14.97200\n",
      "Training Execution time: 489.15006828308105 seconds\n",
      "Inference Execution time: 1.1057026386260986 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "[0]\tvalidation_0-rmse:32.18420\tvalidation_1-rmse:32.29932\n",
      "[50]\tvalidation_0-rmse:9.82450\tvalidation_1-rmse:16.41067\n",
      "[100]\tvalidation_0-rmse:6.83835\tvalidation_1-rmse:15.44940\n",
      "[150]\tvalidation_0-rmse:5.95641\tvalidation_1-rmse:15.24259\n",
      "[200]\tvalidation_0-rmse:5.60093\tvalidation_1-rmse:15.13627\n",
      "[250]\tvalidation_0-rmse:5.25870\tvalidation_1-rmse:15.05503\n",
      "[300]\tvalidation_0-rmse:4.98852\tvalidation_1-rmse:14.95428\n",
      "[350]\tvalidation_0-rmse:4.77477\tvalidation_1-rmse:14.89807\n",
      "[400]\tvalidation_0-rmse:4.58958\tvalidation_1-rmse:14.85214\n",
      "[450]\tvalidation_0-rmse:4.35565\tvalidation_1-rmse:14.76949\n",
      "[477]\tvalidation_0-rmse:4.28733\tvalidation_1-rmse:14.75832\n",
      "Training Execution time: 1151.003847360611 seconds\n",
      "Inference Execution time: 1.8068428039550781 seconds\n",
      "\n",
      "Interaciton #44:\n",
      "{'n_estimators': 1000000, 'max_depth': 12, 'learning_rate': 0.2, 'subsample': 0.5, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.6, 'min_child_weight': 5, 'gamma': 0.1, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:31.58052\tvalidation_1-rmse:31.64859\n",
      "[50]\tvalidation_0-rmse:13.24195\tvalidation_1-rmse:15.00164\n",
      "[100]\tvalidation_0-rmse:12.45080\tvalidation_1-rmse:14.57624\n",
      "[150]\tvalidation_0-rmse:11.76571\tvalidation_1-rmse:14.18022\n",
      "[191]\tvalidation_0-rmse:11.44785\tvalidation_1-rmse:14.06659\n",
      "Training Execution time: 274.0511260032654 seconds\n",
      "Inference Execution time: 0.2697460651397705 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:31.58532\tvalidation_1-rmse:31.66041\n",
      "[50]\tvalidation_0-rmse:13.24526\tvalidation_1-rmse:15.07713\n",
      "[100]\tvalidation_0-rmse:12.54478\tvalidation_1-rmse:14.71464\n",
      "[150]\tvalidation_0-rmse:11.89386\tvalidation_1-rmse:14.32367\n",
      "[190]\tvalidation_0-rmse:11.55589\tvalidation_1-rmse:14.22526\n",
      "Training Execution time: 269.9281828403473 seconds\n",
      "Inference Execution time: 0.2678334712982178 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "[0]\tvalidation_0-rmse:31.59087\tvalidation_1-rmse:31.61228\n",
      "[50]\tvalidation_0-rmse:13.30885\tvalidation_1-rmse:14.99160\n",
      "[100]\tvalidation_0-rmse:12.51626\tvalidation_1-rmse:14.55383\n",
      "[140]\tvalidation_0-rmse:11.88621\tvalidation_1-rmse:14.19663\n",
      "Training Execution time: 197.86525177955627 seconds\n",
      "Inference Execution time: 0.2112278938293457 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "[0]\tvalidation_0-rmse:31.55940\tvalidation_1-rmse:31.75610\n",
      "[50]\tvalidation_0-rmse:13.27310\tvalidation_1-rmse:15.06112\n",
      "[100]\tvalidation_0-rmse:12.46308\tvalidation_1-rmse:14.58384\n",
      "[150]\tvalidation_0-rmse:11.84435\tvalidation_1-rmse:14.22669\n",
      "[190]\tvalidation_0-rmse:11.54383\tvalidation_1-rmse:14.10284\n",
      "Training Execution time: 268.51702308654785 seconds\n",
      "Inference Execution time: 0.3788461685180664 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "[0]\tvalidation_0-rmse:31.60368\tvalidation_1-rmse:31.57004\n",
      "[50]\tvalidation_0-rmse:12.82011\tvalidation_1-rmse:14.62948\n",
      "[100]\tvalidation_0-rmse:12.15953\tvalidation_1-rmse:14.33429\n",
      "[121]\tvalidation_0-rmse:12.01854\tvalidation_1-rmse:14.31550\n",
      "Training Execution time: 176.10807728767395 seconds\n",
      "Inference Execution time: 0.17966127395629883 seconds\n",
      "\n",
      "Interaciton #45:\n",
      "{'n_estimators': 1000000, 'max_depth': 20, 'learning_rate': 0.4, 'subsample': 0.5, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.7999999999999999, 'min_child_weight': 3, 'gamma': 0.1, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:28.92687\tvalidation_1-rmse:30.63664\n",
      "[29]\tvalidation_0-rmse:7.33465\tvalidation_1-rmse:17.68049\n",
      "Training Execution time: 92.05680012702942 seconds\n",
      "Inference Execution time: 0.14797401428222656 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:28.92477\tvalidation_1-rmse:30.60241\n",
      "[30]\tvalidation_0-rmse:7.38937\tvalidation_1-rmse:17.66162\n",
      "Training Execution time: 90.0797975063324 seconds\n",
      "Inference Execution time: 0.17621517181396484 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "[0]\tvalidation_0-rmse:28.89633\tvalidation_1-rmse:30.67544\n",
      "[30]\tvalidation_0-rmse:7.26526\tvalidation_1-rmse:17.70912\n",
      "Training Execution time: 90.4241635799408 seconds\n",
      "Inference Execution time: 0.16784358024597168 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "[0]\tvalidation_0-rmse:28.92781\tvalidation_1-rmse:30.54504\n",
      "[30]\tvalidation_0-rmse:7.29833\tvalidation_1-rmse:17.69617\n",
      "Training Execution time: 91.17482542991638 seconds\n",
      "Inference Execution time: 0.15098094940185547 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "[0]\tvalidation_0-rmse:28.91071\tvalidation_1-rmse:30.68619\n",
      "[33]\tvalidation_0-rmse:7.44122\tvalidation_1-rmse:18.68134\n",
      "Training Execution time: 97.65244460105896 seconds\n",
      "Inference Execution time: 0.1874551773071289 seconds\n",
      "\n",
      "Interaciton #46:\n",
      "{'n_estimators': 1000000, 'max_depth': 16, 'learning_rate': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.7999999999999999, 'min_child_weight': 5, 'gamma': 0.3, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:32.10894\tvalidation_1-rmse:32.32743\n",
      "[50]\tvalidation_0-rmse:10.27233\tvalidation_1-rmse:15.19409\n",
      "[100]\tvalidation_0-rmse:7.75347\tvalidation_1-rmse:14.10951\n",
      "[150]\tvalidation_0-rmse:6.99767\tvalidation_1-rmse:13.74128\n",
      "[200]\tvalidation_0-rmse:6.51275\tvalidation_1-rmse:13.56240\n",
      "[250]\tvalidation_0-rmse:6.29626\tvalidation_1-rmse:13.53249\n",
      "[287]\tvalidation_0-rmse:6.16713\tvalidation_1-rmse:13.51647\n",
      "Training Execution time: 593.0876045227051 seconds\n",
      "Inference Execution time: 1.1516826152801514 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:32.12780\tvalidation_1-rmse:32.23935\n",
      "[50]\tvalidation_0-rmse:10.29159\tvalidation_1-rmse:15.19789\n",
      "[100]\tvalidation_0-rmse:7.75002\tvalidation_1-rmse:14.09944\n",
      "[150]\tvalidation_0-rmse:6.97717\tvalidation_1-rmse:13.69488\n",
      "[200]\tvalidation_0-rmse:6.55043\tvalidation_1-rmse:13.55970\n",
      "[250]\tvalidation_0-rmse:6.31773\tvalidation_1-rmse:13.52260\n",
      "[300]\tvalidation_0-rmse:6.08043\tvalidation_1-rmse:13.46426\n",
      "[350]\tvalidation_0-rmse:5.86913\tvalidation_1-rmse:13.43618\n",
      "[400]\tvalidation_0-rmse:5.67369\tvalidation_1-rmse:13.40686\n",
      "[450]\tvalidation_0-rmse:5.49637\tvalidation_1-rmse:13.37861\n",
      "[459]\tvalidation_0-rmse:5.47482\tvalidation_1-rmse:13.37902\n",
      "Training Execution time: 941.2672970294952 seconds\n",
      "Inference Execution time: 1.586458444595337 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "[0]\tvalidation_0-rmse:32.11882\tvalidation_1-rmse:32.29346\n",
      "[50]\tvalidation_0-rmse:10.29054\tvalidation_1-rmse:15.18475\n",
      "[100]\tvalidation_0-rmse:7.72481\tvalidation_1-rmse:14.07818\n",
      "[150]\tvalidation_0-rmse:7.00258\tvalidation_1-rmse:13.70919\n",
      "[200]\tvalidation_0-rmse:6.59671\tvalidation_1-rmse:13.58132\n",
      "[247]\tvalidation_0-rmse:6.39608\tvalidation_1-rmse:13.54444\n",
      "Training Execution time: 531.2049860954285 seconds\n",
      "Inference Execution time: 1.0294263362884521 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "[0]\tvalidation_0-rmse:32.12103\tvalidation_1-rmse:32.25941\n",
      "[50]\tvalidation_0-rmse:10.30091\tvalidation_1-rmse:15.13906\n",
      "[100]\tvalidation_0-rmse:7.71654\tvalidation_1-rmse:14.04893\n",
      "[150]\tvalidation_0-rmse:6.86664\tvalidation_1-rmse:13.65422\n",
      "[200]\tvalidation_0-rmse:6.62142\tvalidation_1-rmse:13.58576\n",
      "[250]\tvalidation_0-rmse:6.36856\tvalidation_1-rmse:13.51765\n",
      "[300]\tvalidation_0-rmse:6.06631\tvalidation_1-rmse:13.40917\n",
      "[350]\tvalidation_0-rmse:5.82648\tvalidation_1-rmse:13.36949\n",
      "[364]\tvalidation_0-rmse:5.78140\tvalidation_1-rmse:13.36013\n",
      "Training Execution time: 755.7381403446198 seconds\n",
      "Inference Execution time: 1.3531415462493896 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "[0]\tvalidation_0-rmse:32.11447\tvalidation_1-rmse:32.31126\n",
      "[50]\tvalidation_0-rmse:10.05438\tvalidation_1-rmse:15.17560\n",
      "[100]\tvalidation_0-rmse:7.44121\tvalidation_1-rmse:13.98419\n",
      "[150]\tvalidation_0-rmse:7.07955\tvalidation_1-rmse:13.89977\n",
      "[200]\tvalidation_0-rmse:6.79864\tvalidation_1-rmse:13.81908\n",
      "[250]\tvalidation_0-rmse:6.53276\tvalidation_1-rmse:13.73945\n",
      "[252]\tvalidation_0-rmse:6.52534\tvalidation_1-rmse:13.73962\n",
      "Training Execution time: 547.0816736221313 seconds\n",
      "Inference Execution time: 0.9620156288146973 seconds\n",
      "\n",
      "Interaciton #47:\n",
      "{'n_estimators': 1000000, 'max_depth': 16, 'learning_rate': 0.01, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.7999999999999999, 'colsample_bylevel': 0.6, 'min_child_weight': 3, 'gamma': 0.0, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:32.86606\tvalidation_1-rmse:32.80215\n",
      "[50]\tvalidation_0-rmse:23.75145\tvalidation_1-rmse:24.75274\n",
      "[100]\tvalidation_0-rmse:17.78941\tvalidation_1-rmse:19.84713\n",
      "[150]\tvalidation_0-rmse:13.68986\tvalidation_1-rmse:16.72399\n",
      "[200]\tvalidation_0-rmse:11.01735\tvalidation_1-rmse:14.90520\n",
      "[250]\tvalidation_0-rmse:9.42050\tvalidation_1-rmse:13.96305\n",
      "[300]\tvalidation_0-rmse:8.19945\tvalidation_1-rmse:13.29977\n",
      "[350]\tvalidation_0-rmse:7.33425\tvalidation_1-rmse:12.87455\n",
      "[400]\tvalidation_0-rmse:6.66827\tvalidation_1-rmse:12.55762\n",
      "[450]\tvalidation_0-rmse:6.19173\tvalidation_1-rmse:12.35348\n",
      "[500]\tvalidation_0-rmse:5.76733\tvalidation_1-rmse:12.17609\n",
      "[550]\tvalidation_0-rmse:5.46139\tvalidation_1-rmse:12.05878\n",
      "[600]\tvalidation_0-rmse:5.20177\tvalidation_1-rmse:11.95385\n",
      "[650]\tvalidation_0-rmse:4.99188\tvalidation_1-rmse:11.87407\n",
      "[700]\tvalidation_0-rmse:4.82221\tvalidation_1-rmse:11.80699\n",
      "[750]\tvalidation_0-rmse:4.68398\tvalidation_1-rmse:11.75148\n",
      "[800]\tvalidation_0-rmse:4.60385\tvalidation_1-rmse:11.71884\n",
      "[850]\tvalidation_0-rmse:4.53588\tvalidation_1-rmse:11.69033\n",
      "[900]\tvalidation_0-rmse:4.49394\tvalidation_1-rmse:11.67295\n",
      "[950]\tvalidation_0-rmse:4.46263\tvalidation_1-rmse:11.66103\n",
      "[1000]\tvalidation_0-rmse:4.43809\tvalidation_1-rmse:11.65414\n",
      "[1050]\tvalidation_0-rmse:4.42059\tvalidation_1-rmse:11.64937\n",
      "[1100]\tvalidation_0-rmse:4.40587\tvalidation_1-rmse:11.64458\n",
      "[1150]\tvalidation_0-rmse:4.38888\tvalidation_1-rmse:11.64067\n",
      "[1200]\tvalidation_0-rmse:4.37418\tvalidation_1-rmse:11.63706\n",
      "[1250]\tvalidation_0-rmse:4.35612\tvalidation_1-rmse:11.63361\n",
      "[1300]\tvalidation_0-rmse:4.33921\tvalidation_1-rmse:11.63079\n",
      "[1350]\tvalidation_0-rmse:4.31298\tvalidation_1-rmse:11.62468\n",
      "[1400]\tvalidation_0-rmse:4.28190\tvalidation_1-rmse:11.61409\n",
      "[1450]\tvalidation_0-rmse:4.25647\tvalidation_1-rmse:11.60793\n",
      "[1500]\tvalidation_0-rmse:4.23875\tvalidation_1-rmse:11.60394\n",
      "[1550]\tvalidation_0-rmse:4.21583\tvalidation_1-rmse:11.59716\n",
      "[1600]\tvalidation_0-rmse:4.20259\tvalidation_1-rmse:11.59500\n",
      "[1650]\tvalidation_0-rmse:4.18150\tvalidation_1-rmse:11.59072\n",
      "[1700]\tvalidation_0-rmse:4.15836\tvalidation_1-rmse:11.58478\n",
      "[1750]\tvalidation_0-rmse:4.14200\tvalidation_1-rmse:11.58181\n",
      "[1800]\tvalidation_0-rmse:4.12450\tvalidation_1-rmse:11.57889\n",
      "[1850]\tvalidation_0-rmse:4.10863\tvalidation_1-rmse:11.57673\n",
      "[1900]\tvalidation_0-rmse:4.08561\tvalidation_1-rmse:11.57180\n",
      "[1950]\tvalidation_0-rmse:4.06297\tvalidation_1-rmse:11.56608\n",
      "[2000]\tvalidation_0-rmse:4.03867\tvalidation_1-rmse:11.55964\n",
      "[2050]\tvalidation_0-rmse:4.02233\tvalidation_1-rmse:11.55668\n",
      "[2100]\tvalidation_0-rmse:4.00514\tvalidation_1-rmse:11.55391\n",
      "[2150]\tvalidation_0-rmse:3.99064\tvalidation_1-rmse:11.55220\n",
      "[2200]\tvalidation_0-rmse:3.97310\tvalidation_1-rmse:11.54945\n",
      "[2250]\tvalidation_0-rmse:3.95699\tvalidation_1-rmse:11.54683\n",
      "[2300]\tvalidation_0-rmse:3.93855\tvalidation_1-rmse:11.54315\n",
      "[2350]\tvalidation_0-rmse:3.92250\tvalidation_1-rmse:11.54104\n",
      "[2400]\tvalidation_0-rmse:3.90243\tvalidation_1-rmse:11.53723\n",
      "[2450]\tvalidation_0-rmse:3.88572\tvalidation_1-rmse:11.53441\n",
      "[2500]\tvalidation_0-rmse:3.86719\tvalidation_1-rmse:11.53119\n",
      "[2550]\tvalidation_0-rmse:3.85167\tvalidation_1-rmse:11.52890\n",
      "[2600]\tvalidation_0-rmse:3.83665\tvalidation_1-rmse:11.52697\n",
      "[2650]\tvalidation_0-rmse:3.81939\tvalidation_1-rmse:11.52399\n",
      "[2700]\tvalidation_0-rmse:3.80181\tvalidation_1-rmse:11.52021\n",
      "[2750]\tvalidation_0-rmse:3.78691\tvalidation_1-rmse:11.51828\n",
      "[2800]\tvalidation_0-rmse:3.77107\tvalidation_1-rmse:11.51628\n",
      "[2850]\tvalidation_0-rmse:3.75308\tvalidation_1-rmse:11.51393\n",
      "[2900]\tvalidation_0-rmse:3.74069\tvalidation_1-rmse:11.51293\n",
      "[2950]\tvalidation_0-rmse:3.72469\tvalidation_1-rmse:11.51045\n",
      "[3000]\tvalidation_0-rmse:3.70646\tvalidation_1-rmse:11.50687\n",
      "[3050]\tvalidation_0-rmse:3.69163\tvalidation_1-rmse:11.50447\n",
      "[3100]\tvalidation_0-rmse:3.67581\tvalidation_1-rmse:11.50225\n",
      "[3150]\tvalidation_0-rmse:3.66052\tvalidation_1-rmse:11.50048\n",
      "[3200]\tvalidation_0-rmse:3.64602\tvalidation_1-rmse:11.49858\n",
      "[3250]\tvalidation_0-rmse:3.63036\tvalidation_1-rmse:11.49678\n",
      "[3300]\tvalidation_0-rmse:3.61436\tvalidation_1-rmse:11.49432\n",
      "[3350]\tvalidation_0-rmse:3.59856\tvalidation_1-rmse:11.49253\n",
      "[3400]\tvalidation_0-rmse:3.58515\tvalidation_1-rmse:11.49172\n",
      "[3450]\tvalidation_0-rmse:3.57101\tvalidation_1-rmse:11.48902\n",
      "[3500]\tvalidation_0-rmse:3.55669\tvalidation_1-rmse:11.48766\n",
      "[3532]\tvalidation_0-rmse:3.54728\tvalidation_1-rmse:11.48698\n",
      "Training Execution time: 8256.318476200104 seconds\n",
      "Inference Execution time: 13.725540399551392 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:32.84893\tvalidation_1-rmse:32.86806\n",
      "[50]\tvalidation_0-rmse:23.73654\tvalidation_1-rmse:24.80776\n",
      "[100]\tvalidation_0-rmse:17.77434\tvalidation_1-rmse:19.88994\n",
      "[150]\tvalidation_0-rmse:13.67800\tvalidation_1-rmse:16.76526\n",
      "[200]\tvalidation_0-rmse:11.00823\tvalidation_1-rmse:14.94209\n",
      "[250]\tvalidation_0-rmse:9.41352\tvalidation_1-rmse:13.99581\n",
      "[300]\tvalidation_0-rmse:8.18963\tvalidation_1-rmse:13.32968\n",
      "[350]\tvalidation_0-rmse:7.32189\tvalidation_1-rmse:12.90152\n",
      "[400]\tvalidation_0-rmse:6.65664\tvalidation_1-rmse:12.58350\n",
      "[450]\tvalidation_0-rmse:6.18478\tvalidation_1-rmse:12.38008\n",
      "[500]\tvalidation_0-rmse:5.76270\tvalidation_1-rmse:12.20327\n",
      "[550]\tvalidation_0-rmse:5.45747\tvalidation_1-rmse:12.08622\n",
      "[600]\tvalidation_0-rmse:5.19521\tvalidation_1-rmse:11.98098\n",
      "[650]\tvalidation_0-rmse:4.98193\tvalidation_1-rmse:11.89966\n",
      "[700]\tvalidation_0-rmse:4.80768\tvalidation_1-rmse:11.83074\n",
      "[750]\tvalidation_0-rmse:4.68576\tvalidation_1-rmse:11.78229\n",
      "[800]\tvalidation_0-rmse:4.59542\tvalidation_1-rmse:11.74587\n",
      "[850]\tvalidation_0-rmse:4.51577\tvalidation_1-rmse:11.71369\n",
      "[900]\tvalidation_0-rmse:4.46550\tvalidation_1-rmse:11.69307\n",
      "[950]\tvalidation_0-rmse:4.43392\tvalidation_1-rmse:11.68059\n",
      "[1000]\tvalidation_0-rmse:4.41419\tvalidation_1-rmse:11.67523\n",
      "[1050]\tvalidation_0-rmse:4.39644\tvalidation_1-rmse:11.66975\n",
      "[1100]\tvalidation_0-rmse:4.37912\tvalidation_1-rmse:11.66526\n",
      "[1150]\tvalidation_0-rmse:4.36484\tvalidation_1-rmse:11.66207\n",
      "[1200]\tvalidation_0-rmse:4.34159\tvalidation_1-rmse:11.65432\n",
      "[1250]\tvalidation_0-rmse:4.32696\tvalidation_1-rmse:11.65145\n",
      "[1300]\tvalidation_0-rmse:4.30825\tvalidation_1-rmse:11.64724\n",
      "[1350]\tvalidation_0-rmse:4.28798\tvalidation_1-rmse:11.64315\n",
      "[1400]\tvalidation_0-rmse:4.26500\tvalidation_1-rmse:11.63765\n",
      "[1450]\tvalidation_0-rmse:4.24275\tvalidation_1-rmse:11.63152\n",
      "[1500]\tvalidation_0-rmse:4.22691\tvalidation_1-rmse:11.62837\n",
      "[1550]\tvalidation_0-rmse:4.20687\tvalidation_1-rmse:11.62415\n",
      "[1600]\tvalidation_0-rmse:4.18696\tvalidation_1-rmse:11.61993\n",
      "[1650]\tvalidation_0-rmse:4.16703\tvalidation_1-rmse:11.61681\n",
      "[1700]\tvalidation_0-rmse:4.14421\tvalidation_1-rmse:11.61095\n",
      "[1750]\tvalidation_0-rmse:4.12259\tvalidation_1-rmse:11.60613\n",
      "[1800]\tvalidation_0-rmse:4.10353\tvalidation_1-rmse:11.60265\n",
      "[1850]\tvalidation_0-rmse:4.08448\tvalidation_1-rmse:11.59973\n",
      "[1900]\tvalidation_0-rmse:4.06375\tvalidation_1-rmse:11.59525\n",
      "[1950]\tvalidation_0-rmse:4.04403\tvalidation_1-rmse:11.59096\n",
      "[2000]\tvalidation_0-rmse:4.02357\tvalidation_1-rmse:11.58653\n",
      "[2050]\tvalidation_0-rmse:4.00755\tvalidation_1-rmse:11.58378\n",
      "[2100]\tvalidation_0-rmse:3.98836\tvalidation_1-rmse:11.58045\n",
      "[2150]\tvalidation_0-rmse:3.97093\tvalidation_1-rmse:11.57829\n",
      "[2200]\tvalidation_0-rmse:3.94701\tvalidation_1-rmse:11.57350\n",
      "[2250]\tvalidation_0-rmse:3.92997\tvalidation_1-rmse:11.57152\n",
      "[2300]\tvalidation_0-rmse:3.90536\tvalidation_1-rmse:11.56514\n",
      "[2350]\tvalidation_0-rmse:3.89050\tvalidation_1-rmse:11.56351\n",
      "[2400]\tvalidation_0-rmse:3.87387\tvalidation_1-rmse:11.56065\n",
      "[2450]\tvalidation_0-rmse:3.85539\tvalidation_1-rmse:11.55780\n",
      "[2500]\tvalidation_0-rmse:3.83914\tvalidation_1-rmse:11.55596\n",
      "[2550]\tvalidation_0-rmse:3.82257\tvalidation_1-rmse:11.55312\n",
      "[2600]\tvalidation_0-rmse:3.80666\tvalidation_1-rmse:11.55086\n",
      "[2650]\tvalidation_0-rmse:3.79223\tvalidation_1-rmse:11.54933\n",
      "[2700]\tvalidation_0-rmse:3.77374\tvalidation_1-rmse:11.54589\n",
      "[2750]\tvalidation_0-rmse:3.75752\tvalidation_1-rmse:11.54411\n",
      "[2800]\tvalidation_0-rmse:3.74147\tvalidation_1-rmse:11.54219\n",
      "[2850]\tvalidation_0-rmse:3.72349\tvalidation_1-rmse:11.53978\n",
      "[2900]\tvalidation_0-rmse:3.70723\tvalidation_1-rmse:11.53808\n",
      "[2950]\tvalidation_0-rmse:3.69123\tvalidation_1-rmse:11.53655\n",
      "[3000]\tvalidation_0-rmse:3.67536\tvalidation_1-rmse:11.53410\n",
      "[3050]\tvalidation_0-rmse:3.65826\tvalidation_1-rmse:11.53168\n",
      "[3100]\tvalidation_0-rmse:3.64368\tvalidation_1-rmse:11.52956\n",
      "[3150]\tvalidation_0-rmse:3.62600\tvalidation_1-rmse:11.52667\n",
      "[3200]\tvalidation_0-rmse:3.60862\tvalidation_1-rmse:11.52448\n",
      "[3250]\tvalidation_0-rmse:3.59300\tvalidation_1-rmse:11.52188\n",
      "[3300]\tvalidation_0-rmse:3.57667\tvalidation_1-rmse:11.51949\n",
      "[3350]\tvalidation_0-rmse:3.56036\tvalidation_1-rmse:11.51746\n",
      "[3400]\tvalidation_0-rmse:3.54692\tvalidation_1-rmse:11.51629\n",
      "[3405]\tvalidation_0-rmse:3.54576\tvalidation_1-rmse:11.51629\n",
      "Training Execution time: 8132.907669782639 seconds\n",
      "Inference Execution time: 13.881842613220215 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "[0]\tvalidation_0-rmse:32.84632\tvalidation_1-rmse:32.88087\n",
      "[50]\tvalidation_0-rmse:23.73423\tvalidation_1-rmse:24.81244\n",
      "[100]\tvalidation_0-rmse:17.77689\tvalidation_1-rmse:19.89505\n",
      "[150]\tvalidation_0-rmse:13.67681\tvalidation_1-rmse:16.76179\n",
      "[200]\tvalidation_0-rmse:11.00637\tvalidation_1-rmse:14.93517\n",
      "[250]\tvalidation_0-rmse:9.41216\tvalidation_1-rmse:13.98687\n",
      "[300]\tvalidation_0-rmse:8.18589\tvalidation_1-rmse:13.31883\n",
      "[350]\tvalidation_0-rmse:7.32040\tvalidation_1-rmse:12.89023\n",
      "[400]\tvalidation_0-rmse:6.65792\tvalidation_1-rmse:12.57183\n",
      "[450]\tvalidation_0-rmse:6.18476\tvalidation_1-rmse:12.36789\n",
      "[500]\tvalidation_0-rmse:5.76412\tvalidation_1-rmse:12.19025\n",
      "[550]\tvalidation_0-rmse:5.45818\tvalidation_1-rmse:12.07202\n",
      "[600]\tvalidation_0-rmse:5.19702\tvalidation_1-rmse:11.96642\n",
      "[650]\tvalidation_0-rmse:4.98713\tvalidation_1-rmse:11.88468\n",
      "[700]\tvalidation_0-rmse:4.81274\tvalidation_1-rmse:11.81521\n",
      "[750]\tvalidation_0-rmse:4.68226\tvalidation_1-rmse:11.76348\n",
      "[800]\tvalidation_0-rmse:4.60155\tvalidation_1-rmse:11.73108\n",
      "[850]\tvalidation_0-rmse:4.53825\tvalidation_1-rmse:11.70519\n",
      "[900]\tvalidation_0-rmse:4.49373\tvalidation_1-rmse:11.68762\n",
      "[950]\tvalidation_0-rmse:4.45537\tvalidation_1-rmse:11.67276\n",
      "[1000]\tvalidation_0-rmse:4.43290\tvalidation_1-rmse:11.66528\n",
      "[1050]\tvalidation_0-rmse:4.41789\tvalidation_1-rmse:11.66086\n",
      "[1100]\tvalidation_0-rmse:4.40322\tvalidation_1-rmse:11.65737\n",
      "[1150]\tvalidation_0-rmse:4.38026\tvalidation_1-rmse:11.65050\n",
      "[1200]\tvalidation_0-rmse:4.36235\tvalidation_1-rmse:11.64607\n",
      "[1250]\tvalidation_0-rmse:4.34640\tvalidation_1-rmse:11.64246\n",
      "[1300]\tvalidation_0-rmse:4.32598\tvalidation_1-rmse:11.63741\n",
      "[1350]\tvalidation_0-rmse:4.30812\tvalidation_1-rmse:11.63247\n",
      "[1400]\tvalidation_0-rmse:4.28195\tvalidation_1-rmse:11.62383\n",
      "[1450]\tvalidation_0-rmse:4.24746\tvalidation_1-rmse:11.61204\n",
      "[1500]\tvalidation_0-rmse:4.22238\tvalidation_1-rmse:11.60597\n",
      "[1550]\tvalidation_0-rmse:4.20497\tvalidation_1-rmse:11.60132\n",
      "[1600]\tvalidation_0-rmse:4.19190\tvalidation_1-rmse:11.59980\n",
      "[1650]\tvalidation_0-rmse:4.16869\tvalidation_1-rmse:11.59460\n",
      "[1700]\tvalidation_0-rmse:4.14071\tvalidation_1-rmse:11.58676\n",
      "[1750]\tvalidation_0-rmse:4.11455\tvalidation_1-rmse:11.57911\n",
      "[1800]\tvalidation_0-rmse:4.09810\tvalidation_1-rmse:11.57716\n",
      "[1850]\tvalidation_0-rmse:4.07908\tvalidation_1-rmse:11.57390\n",
      "[1900]\tvalidation_0-rmse:4.06172\tvalidation_1-rmse:11.57111\n",
      "[1950]\tvalidation_0-rmse:4.04293\tvalidation_1-rmse:11.56714\n",
      "[2000]\tvalidation_0-rmse:4.02132\tvalidation_1-rmse:11.56216\n",
      "[2050]\tvalidation_0-rmse:4.00150\tvalidation_1-rmse:11.55851\n",
      "[2100]\tvalidation_0-rmse:3.98310\tvalidation_1-rmse:11.55369\n",
      "[2150]\tvalidation_0-rmse:3.96133\tvalidation_1-rmse:11.54979\n",
      "[2200]\tvalidation_0-rmse:3.94551\tvalidation_1-rmse:11.54783\n",
      "[2250]\tvalidation_0-rmse:3.92805\tvalidation_1-rmse:11.54465\n",
      "[2300]\tvalidation_0-rmse:3.91473\tvalidation_1-rmse:11.54276\n",
      "[2350]\tvalidation_0-rmse:3.89624\tvalidation_1-rmse:11.53939\n",
      "[2400]\tvalidation_0-rmse:3.88204\tvalidation_1-rmse:11.53776\n",
      "[2450]\tvalidation_0-rmse:3.86602\tvalidation_1-rmse:11.53514\n",
      "[2500]\tvalidation_0-rmse:3.84320\tvalidation_1-rmse:11.53014\n",
      "[2550]\tvalidation_0-rmse:3.82530\tvalidation_1-rmse:11.52747\n",
      "[2600]\tvalidation_0-rmse:3.80927\tvalidation_1-rmse:11.52474\n",
      "[2650]\tvalidation_0-rmse:3.79081\tvalidation_1-rmse:11.52194\n",
      "[2700]\tvalidation_0-rmse:3.76979\tvalidation_1-rmse:11.51784\n",
      "[2750]\tvalidation_0-rmse:3.75716\tvalidation_1-rmse:11.51675\n",
      "[2800]\tvalidation_0-rmse:3.74237\tvalidation_1-rmse:11.51492\n",
      "[2850]\tvalidation_0-rmse:3.72215\tvalidation_1-rmse:11.51141\n",
      "[2900]\tvalidation_0-rmse:3.70645\tvalidation_1-rmse:11.50929\n",
      "[2950]\tvalidation_0-rmse:3.68715\tvalidation_1-rmse:11.50579\n",
      "[3000]\tvalidation_0-rmse:3.67489\tvalidation_1-rmse:11.50487\n",
      "[3050]\tvalidation_0-rmse:3.65898\tvalidation_1-rmse:11.50291\n",
      "[3100]\tvalidation_0-rmse:3.64195\tvalidation_1-rmse:11.50101\n",
      "[3132]\tvalidation_0-rmse:3.63223\tvalidation_1-rmse:11.49960\n",
      "Training Execution time: 7496.7103571891785 seconds\n",
      "Inference Execution time: 12.839712381362915 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "[0]\tvalidation_0-rmse:32.83441\tvalidation_1-rmse:32.92587\n",
      "[50]\tvalidation_0-rmse:23.72722\tvalidation_1-rmse:24.84376\n",
      "[100]\tvalidation_0-rmse:17.77003\tvalidation_1-rmse:19.91297\n",
      "[150]\tvalidation_0-rmse:13.67518\tvalidation_1-rmse:16.77491\n",
      "[200]\tvalidation_0-rmse:11.00441\tvalidation_1-rmse:14.94651\n",
      "[250]\tvalidation_0-rmse:9.40940\tvalidation_1-rmse:14.00033\n",
      "[300]\tvalidation_0-rmse:8.18457\tvalidation_1-rmse:13.33072\n",
      "[350]\tvalidation_0-rmse:7.31591\tvalidation_1-rmse:12.90151\n",
      "[400]\tvalidation_0-rmse:6.65224\tvalidation_1-rmse:12.58478\n",
      "[450]\tvalidation_0-rmse:6.17814\tvalidation_1-rmse:12.38180\n",
      "[500]\tvalidation_0-rmse:5.75645\tvalidation_1-rmse:12.20411\n",
      "[550]\tvalidation_0-rmse:5.45161\tvalidation_1-rmse:12.08708\n",
      "[600]\tvalidation_0-rmse:5.19113\tvalidation_1-rmse:11.98166\n",
      "[650]\tvalidation_0-rmse:4.98591\tvalidation_1-rmse:11.90351\n",
      "[700]\tvalidation_0-rmse:4.82222\tvalidation_1-rmse:11.83820\n",
      "[750]\tvalidation_0-rmse:4.69709\tvalidation_1-rmse:11.78855\n",
      "[800]\tvalidation_0-rmse:4.60909\tvalidation_1-rmse:11.75135\n",
      "[850]\tvalidation_0-rmse:4.53147\tvalidation_1-rmse:11.71910\n",
      "[900]\tvalidation_0-rmse:4.47905\tvalidation_1-rmse:11.69801\n",
      "[950]\tvalidation_0-rmse:4.44735\tvalidation_1-rmse:11.68686\n",
      "[1000]\tvalidation_0-rmse:4.42702\tvalidation_1-rmse:11.68041\n",
      "[1050]\tvalidation_0-rmse:4.40990\tvalidation_1-rmse:11.67513\n",
      "[1100]\tvalidation_0-rmse:4.39242\tvalidation_1-rmse:11.67101\n",
      "[1150]\tvalidation_0-rmse:4.36688\tvalidation_1-rmse:11.66262\n",
      "[1200]\tvalidation_0-rmse:4.35291\tvalidation_1-rmse:11.65942\n",
      "[1250]\tvalidation_0-rmse:4.33626\tvalidation_1-rmse:11.65543\n",
      "[1300]\tvalidation_0-rmse:4.31678\tvalidation_1-rmse:11.65005\n",
      "[1350]\tvalidation_0-rmse:4.29882\tvalidation_1-rmse:11.64599\n",
      "[1400]\tvalidation_0-rmse:4.27853\tvalidation_1-rmse:11.64011\n",
      "[1450]\tvalidation_0-rmse:4.25916\tvalidation_1-rmse:11.63559\n",
      "[1500]\tvalidation_0-rmse:4.24040\tvalidation_1-rmse:11.63176\n",
      "[1550]\tvalidation_0-rmse:4.22333\tvalidation_1-rmse:11.62811\n",
      "[1600]\tvalidation_0-rmse:4.20472\tvalidation_1-rmse:11.62428\n",
      "[1650]\tvalidation_0-rmse:4.18527\tvalidation_1-rmse:11.61859\n",
      "[1700]\tvalidation_0-rmse:4.16332\tvalidation_1-rmse:11.61362\n",
      "[1750]\tvalidation_0-rmse:4.14158\tvalidation_1-rmse:11.60780\n",
      "[1800]\tvalidation_0-rmse:4.12359\tvalidation_1-rmse:11.60468\n",
      "[1850]\tvalidation_0-rmse:4.10211\tvalidation_1-rmse:11.60075\n",
      "[1900]\tvalidation_0-rmse:4.08172\tvalidation_1-rmse:11.59657\n",
      "[1950]\tvalidation_0-rmse:4.06077\tvalidation_1-rmse:11.59172\n",
      "[2000]\tvalidation_0-rmse:4.04634\tvalidation_1-rmse:11.58989\n",
      "[2050]\tvalidation_0-rmse:4.03020\tvalidation_1-rmse:11.58780\n",
      "[2100]\tvalidation_0-rmse:4.01468\tvalidation_1-rmse:11.58542\n",
      "[2150]\tvalidation_0-rmse:3.99858\tvalidation_1-rmse:11.58254\n",
      "[2200]\tvalidation_0-rmse:3.97885\tvalidation_1-rmse:11.57878\n",
      "[2250]\tvalidation_0-rmse:3.95918\tvalidation_1-rmse:11.57517\n",
      "[2300]\tvalidation_0-rmse:3.94024\tvalidation_1-rmse:11.57219\n",
      "[2350]\tvalidation_0-rmse:3.92400\tvalidation_1-rmse:11.56936\n",
      "[2400]\tvalidation_0-rmse:3.90127\tvalidation_1-rmse:11.56417\n",
      "[2450]\tvalidation_0-rmse:3.88526\tvalidation_1-rmse:11.56156\n",
      "[2500]\tvalidation_0-rmse:3.86698\tvalidation_1-rmse:11.55887\n",
      "[2550]\tvalidation_0-rmse:3.84833\tvalidation_1-rmse:11.55588\n",
      "[2600]\tvalidation_0-rmse:3.82918\tvalidation_1-rmse:11.55230\n",
      "[2650]\tvalidation_0-rmse:3.81211\tvalidation_1-rmse:11.55027\n",
      "[2700]\tvalidation_0-rmse:3.79863\tvalidation_1-rmse:11.54876\n",
      "[2750]\tvalidation_0-rmse:3.78211\tvalidation_1-rmse:11.54634\n",
      "[2800]\tvalidation_0-rmse:3.76494\tvalidation_1-rmse:11.54371\n",
      "[2850]\tvalidation_0-rmse:3.74735\tvalidation_1-rmse:11.54091\n",
      "[2900]\tvalidation_0-rmse:3.72805\tvalidation_1-rmse:11.53803\n",
      "[2950]\tvalidation_0-rmse:3.71159\tvalidation_1-rmse:11.53566\n",
      "[3000]\tvalidation_0-rmse:3.69847\tvalidation_1-rmse:11.53451\n",
      "[3050]\tvalidation_0-rmse:3.68353\tvalidation_1-rmse:11.53308\n",
      "[3100]\tvalidation_0-rmse:3.66775\tvalidation_1-rmse:11.53107\n",
      "[3150]\tvalidation_0-rmse:3.65092\tvalidation_1-rmse:11.52827\n",
      "[3168]\tvalidation_0-rmse:3.64736\tvalidation_1-rmse:11.52799\n",
      "Training Execution time: 7518.771095991135 seconds\n",
      "Inference Execution time: 13.055976867675781 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "[0]\tvalidation_0-rmse:32.85145\tvalidation_1-rmse:32.85929\n",
      "[50]\tvalidation_0-rmse:24.08603\tvalidation_1-rmse:25.18587\n",
      "[100]\tvalidation_0-rmse:17.47722\tvalidation_1-rmse:19.61524\n",
      "[150]\tvalidation_0-rmse:13.54516\tvalidation_1-rmse:16.68800\n",
      "[200]\tvalidation_0-rmse:11.00444\tvalidation_1-rmse:14.99159\n",
      "[250]\tvalidation_0-rmse:9.22143\tvalidation_1-rmse:13.89837\n",
      "[300]\tvalidation_0-rmse:8.14647\tvalidation_1-rmse:13.34460\n",
      "[350]\tvalidation_0-rmse:7.25017\tvalidation_1-rmse:12.88547\n",
      "[400]\tvalidation_0-rmse:6.62720\tvalidation_1-rmse:12.60471\n",
      "[450]\tvalidation_0-rmse:6.09185\tvalidation_1-rmse:12.35583\n",
      "[500]\tvalidation_0-rmse:5.71595\tvalidation_1-rmse:12.20805\n",
      "[550]\tvalidation_0-rmse:5.38008\tvalidation_1-rmse:12.06540\n",
      "[600]\tvalidation_0-rmse:5.14862\tvalidation_1-rmse:11.97701\n",
      "[650]\tvalidation_0-rmse:4.92986\tvalidation_1-rmse:11.88417\n",
      "[700]\tvalidation_0-rmse:4.76740\tvalidation_1-rmse:11.81595\n",
      "[750]\tvalidation_0-rmse:4.65555\tvalidation_1-rmse:11.76810\n",
      "[800]\tvalidation_0-rmse:4.57796\tvalidation_1-rmse:11.73695\n",
      "[850]\tvalidation_0-rmse:4.52817\tvalidation_1-rmse:11.71764\n",
      "[900]\tvalidation_0-rmse:4.48355\tvalidation_1-rmse:11.70052\n",
      "[950]\tvalidation_0-rmse:4.45114\tvalidation_1-rmse:11.68531\n",
      "[1000]\tvalidation_0-rmse:4.43099\tvalidation_1-rmse:11.67929\n",
      "[1050]\tvalidation_0-rmse:4.41642\tvalidation_1-rmse:11.67465\n",
      "[1100]\tvalidation_0-rmse:4.39525\tvalidation_1-rmse:11.66812\n",
      "[1150]\tvalidation_0-rmse:4.38130\tvalidation_1-rmse:11.66481\n",
      "[1200]\tvalidation_0-rmse:4.36041\tvalidation_1-rmse:11.65919\n",
      "[1250]\tvalidation_0-rmse:4.34410\tvalidation_1-rmse:11.65570\n",
      "[1300]\tvalidation_0-rmse:4.32322\tvalidation_1-rmse:11.64902\n",
      "[1350]\tvalidation_0-rmse:4.29730\tvalidation_1-rmse:11.64104\n",
      "[1400]\tvalidation_0-rmse:4.27535\tvalidation_1-rmse:11.63616\n",
      "[1450]\tvalidation_0-rmse:4.25554\tvalidation_1-rmse:11.63177\n",
      "[1500]\tvalidation_0-rmse:4.23300\tvalidation_1-rmse:11.62664\n",
      "[1550]\tvalidation_0-rmse:4.21233\tvalidation_1-rmse:11.62143\n",
      "[1600]\tvalidation_0-rmse:4.19286\tvalidation_1-rmse:11.61653\n",
      "[1650]\tvalidation_0-rmse:4.16979\tvalidation_1-rmse:11.61104\n",
      "[1700]\tvalidation_0-rmse:4.14958\tvalidation_1-rmse:11.60736\n",
      "[1750]\tvalidation_0-rmse:4.13324\tvalidation_1-rmse:11.60499\n",
      "[1800]\tvalidation_0-rmse:4.10801\tvalidation_1-rmse:11.59997\n",
      "[1850]\tvalidation_0-rmse:4.08964\tvalidation_1-rmse:11.59754\n",
      "[1900]\tvalidation_0-rmse:4.06972\tvalidation_1-rmse:11.59436\n",
      "[1950]\tvalidation_0-rmse:4.05421\tvalidation_1-rmse:11.59143\n",
      "[2000]\tvalidation_0-rmse:4.03667\tvalidation_1-rmse:11.58824\n",
      "[2050]\tvalidation_0-rmse:4.01872\tvalidation_1-rmse:11.58600\n",
      "[2100]\tvalidation_0-rmse:4.00119\tvalidation_1-rmse:11.58368\n",
      "[2150]\tvalidation_0-rmse:3.98454\tvalidation_1-rmse:11.58128\n",
      "[2200]\tvalidation_0-rmse:3.97006\tvalidation_1-rmse:11.58025\n",
      "[2250]\tvalidation_0-rmse:3.94836\tvalidation_1-rmse:11.57513\n",
      "[2300]\tvalidation_0-rmse:3.93052\tvalidation_1-rmse:11.57223\n",
      "[2350]\tvalidation_0-rmse:3.90573\tvalidation_1-rmse:11.56605\n",
      "[2400]\tvalidation_0-rmse:3.88448\tvalidation_1-rmse:11.56080\n",
      "[2450]\tvalidation_0-rmse:3.86724\tvalidation_1-rmse:11.55867\n",
      "[2500]\tvalidation_0-rmse:3.84596\tvalidation_1-rmse:11.55402\n",
      "[2550]\tvalidation_0-rmse:3.82781\tvalidation_1-rmse:11.55166\n",
      "[2600]\tvalidation_0-rmse:3.81246\tvalidation_1-rmse:11.54905\n",
      "[2650]\tvalidation_0-rmse:3.79887\tvalidation_1-rmse:11.54809\n",
      "[2700]\tvalidation_0-rmse:3.78167\tvalidation_1-rmse:11.54561\n",
      "[2750]\tvalidation_0-rmse:3.76479\tvalidation_1-rmse:11.54368\n",
      "[2800]\tvalidation_0-rmse:3.75059\tvalidation_1-rmse:11.54219\n",
      "[2850]\tvalidation_0-rmse:3.73654\tvalidation_1-rmse:11.54105\n",
      "[2900]\tvalidation_0-rmse:3.72012\tvalidation_1-rmse:11.53769\n",
      "[2950]\tvalidation_0-rmse:3.70023\tvalidation_1-rmse:11.53404\n",
      "[3000]\tvalidation_0-rmse:3.68581\tvalidation_1-rmse:11.53231\n",
      "[3050]\tvalidation_0-rmse:3.66922\tvalidation_1-rmse:11.52978\n",
      "[3100]\tvalidation_0-rmse:3.65435\tvalidation_1-rmse:11.52788\n",
      "[3150]\tvalidation_0-rmse:3.63727\tvalidation_1-rmse:11.52509\n",
      "[3200]\tvalidation_0-rmse:3.62426\tvalidation_1-rmse:11.52424\n",
      "[3250]\tvalidation_0-rmse:3.60792\tvalidation_1-rmse:11.52192\n",
      "[3300]\tvalidation_0-rmse:3.59068\tvalidation_1-rmse:11.51916\n",
      "[3350]\tvalidation_0-rmse:3.57717\tvalidation_1-rmse:11.51732\n",
      "[3400]\tvalidation_0-rmse:3.56125\tvalidation_1-rmse:11.51561\n",
      "[3450]\tvalidation_0-rmse:3.54460\tvalidation_1-rmse:11.51353\n",
      "[3500]\tvalidation_0-rmse:3.53090\tvalidation_1-rmse:11.51210\n",
      "[3550]\tvalidation_0-rmse:3.51754\tvalidation_1-rmse:11.51108\n",
      "[3600]\tvalidation_0-rmse:3.50479\tvalidation_1-rmse:11.51028\n",
      "[3650]\tvalidation_0-rmse:3.48941\tvalidation_1-rmse:11.50845\n",
      "[3700]\tvalidation_0-rmse:3.47588\tvalidation_1-rmse:11.50668\n",
      "[3750]\tvalidation_0-rmse:3.46012\tvalidation_1-rmse:11.50473\n",
      "[3789]\tvalidation_0-rmse:3.44662\tvalidation_1-rmse:11.50280\n",
      "Training Execution time: 8872.591758489609 seconds\n",
      "Inference Execution time: 14.573236227035522 seconds\n",
      "\n",
      "Interaciton #48:\n",
      "{'n_estimators': 1000000, 'max_depth': 20, 'learning_rate': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.7, 'min_child_weight': 3, 'gamma': 0.1, 'n_jobs': -1}\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "[0]\tvalidation_0-rmse:31.87640\tvalidation_1-rmse:32.37969\n",
      "[50]\tvalidation_0-rmse:6.21747\tvalidation_1-rmse:16.27207\n",
      "[100]\tvalidation_0-rmse:3.30424\tvalidation_1-rmse:15.47448\n",
      "[150]\tvalidation_0-rmse:2.35667\tvalidation_1-rmse:15.20429\n",
      "[200]\tvalidation_0-rmse:2.06132\tvalidation_1-rmse:15.12607\n",
      "[250]\tvalidation_0-rmse:1.90370\tvalidation_1-rmse:15.10405\n",
      "[300]\tvalidation_0-rmse:1.73269\tvalidation_1-rmse:15.07099\n",
      "[350]\tvalidation_0-rmse:1.62124\tvalidation_1-rmse:15.06073\n",
      "[400]\tvalidation_0-rmse:1.50259\tvalidation_1-rmse:15.04746\n",
      "[450]\tvalidation_0-rmse:1.41518\tvalidation_1-rmse:15.03823\n",
      "[459]\tvalidation_0-rmse:1.40528\tvalidation_1-rmse:15.03826\n",
      "Training Execution time: 1347.6540088653564 seconds\n",
      "Inference Execution time: 2.928239583969116 seconds\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "[0]\tvalidation_0-rmse:31.86500\tvalidation_1-rmse:32.36834\n",
      "[50]\tvalidation_0-rmse:6.20523\tvalidation_1-rmse:16.28016\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,n_iter+1):\n",
    "    if n<=42:\n",
    "        continue\n",
    "        \n",
    "    print(f'\\nInteraciton #{n}:')\n",
    "\n",
    "    metrics = pd.DataFrame(columns=['fold', 'mae', 'mse', 'rmse', 'r2', 'training_time', 'inference_time'])\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    \n",
    "    # Choosing the hyperparameters\n",
    "    params_chosen = {}\n",
    "    for id, item in params.items():\n",
    "        params_chosen[id] = random.choice(item)\n",
    "    print(params_chosen)\n",
    "    # Saving the hyperparameters\n",
    "    save_dict_csv(params_chosen, f'./hyperparameters/', f'{n}')\n",
    "    \n",
    "    # Training\n",
    "    for train, val in kfold.split(X_train, y_train):\n",
    "                \n",
    "        # Define the model as the best model from the random search\n",
    "        model = xgb.XGBRegressor(**params_chosen)\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "        # get the start time\n",
    "        st_wall = time.time()\n",
    "        \n",
    "        # Fit data to model\n",
    "        model.fit(X_train[train], y_train[train], eval_metric=['rmse'], verbose=50, eval_set=[(X_train[train], y_train[train]), (X_train[val], y_train[val])], early_stopping_rounds=patience)\n",
    "\n",
    "        # get the end time\n",
    "        et_wall = time.time()\n",
    "\n",
    "        # get execution time\n",
    "        wall_time = et_wall - st_wall\n",
    "\n",
    "        print('Training Execution time:', wall_time, 'seconds')\n",
    "\n",
    "        # get the start time\n",
    "        st_wall_inf = time.time()\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # get the end time\n",
    "        et_wall_inf = time.time()\n",
    "\n",
    "        # get execution time\n",
    "        wall_time_inf = et_wall_inf - st_wall_inf\n",
    "\n",
    "        print('Inference Execution time:', wall_time_inf, 'seconds')\n",
    "\n",
    "        scores = [fold_no, mean_absolute_error(y_test, y_pred), mean_squared_error(y_test, y_pred), \n",
    "                  sqrt(mean_squared_error(y_test, y_pred)), r2_score(y_test, y_pred), wall_time, wall_time_inf]\n",
    "\n",
    "        metrics.loc[len(metrics)] = scores\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "    metrics.loc[len(metrics)] = ['mean', metrics['mae'].mean(), metrics['mse'].mean(), metrics['rmse'].mean(), metrics['r2'].mean(), metrics['training_time'].mean(), metrics['inference_time'].mean()]\n",
    "    metrics.loc[len(metrics)] = ['std', metrics['mae'].iloc[:-1].std(), metrics['mse'].iloc[:-1].std(), metrics['rmse'].iloc[:-1].std(), metrics['r2'].iloc[:-1].std(), metrics['training_time'].iloc[:-1].std(), metrics['inference_time'].iloc[:-1].std()]  \n",
    "    metrics.loc[len(metrics)] = ['sum', metrics['mae'].iloc[:-2].sum(), metrics['mse'].iloc[:-2].sum(), metrics['rmse'].iloc[:-2].sum(), metrics['r2'].iloc[:-2].sum(), metrics['training_time'].iloc[:-2].sum(), metrics['inference_time'].iloc[:-2].sum()]\n",
    "    metrics = metrics.set_index('fold')\n",
    "\n",
    "    path_to_save = f'./results/'\n",
    "\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    metrics.to_csv(f'{path_to_save}{n}.csv')\n",
    "    \n",
    "    path_to_save = f'./models/'\n",
    "\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "    \n",
    "    # save model to file\n",
    "    joblib.dump(model, f'{path_to_save}{n}.dat');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
